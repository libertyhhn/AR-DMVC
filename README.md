# AR-DMVC-AM
Official implementation of the ICML'24 paper "[Adversarially Robust Deep Multi-View Clustering: A Novel Attack and Defense Framework](https://openreview.net/forum?id=D9EfAkQCzh)".

## Preparing datasets
The multi-view dataset NoisyMNIST, NoisyFashion, and PatchedMNIST can be generated by running
```
python -m data.make_dataset noisymnist noisyfashionmnist patchedmnist
```
The RegDB dataset can be obtained through [paper](https://www.mdpi.com/186516).

## Running experiments
To train the proposed AR-DMVC-AM or AR-DMVC on the provided dataset, e.g., NoisyMNIST, execute:
```
python run.py --model_name ardmvc_am --data_name noisymnist
```
or
```
python run.py --model_name ardmvc --data_name noisymnist
```
To experiment with other deep multi-view clustering methods, run:
```
python run_other.py --model_name <model name> --data_name noisymnist
```
where `<model name>` refers to the name of deep multi-view models in the program, as shown in the table below compared to the article:

| Name in paper | Name in program |
|---------------|-----------------|
| EAMC          | `eamc`          |
| SiMVC         | `simvc`         |
| CoMVC         | `comvc`         |
| Multi-VAE     | `mvae`          |
| AECoDDC       | `cae`           |
| InfoDDC       | `mimvc`         |
| SEM           | `SEM`           |

## Printing images
To print the adversarial samples of different deep multi-view models after running the experiment, run:
```
python atk_plot.py --model_name ardmvc_am --data_name noisymnist
```
The images will all be saved in `atk_plot`.

## Citation
If you think our work is useful, please consider citing:
```bibtex
@inproceedings{huang2024adversarially,
title={Adversarially Robust Deep Multi-View Clustering: A Novel Attack and Defense Framework},
author={Huang, Haonan and Zhou, Guoxu and Zheng, Yanghang and Qiu, Yuning and Wang, Andong and Zhao, Qibin},
booktitle={International Conference on Machine Learning},
year={2024},
organization={PMLR}
}
```
## Contact
If you have any questions or feedback, please feel free to contact us at libertyhhn@foxmail.com (Haonan Huang, GDUT) or illusionzyh@foxmail.com (Yanghang Zheng, GDUT).
